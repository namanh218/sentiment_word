{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_of_word.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odEgovpvGUd5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78af9MdgogxO",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://greenbookblog.org/wp-content/uploads/2017/02/trump-word-cloud.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0zzagchortM",
        "colab_type": "text"
      },
      "source": [
        "GROUP DICKY AND CUONG\n",
        "\n",
        "\n",
        "1. Main quest: Using dataset from kaggle to classification the sentiment of words.\n",
        "2. Using: TF IDF learn from last week to apply in this problem.\n",
        "\n",
        "*   First import dataframe for 2 dataset\n",
        "*   Clean the dataset\n",
        "*   Creat func clean word\n",
        "*   Check in the stop word\n",
        "*   Run logistic regressiob\n",
        "*   Export file and upload to kaggle\n",
        "\n",
        "3. Conclusion: TFIDF can recongnize 60% meaning word in stop word within you can clean the data good. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyhCa-hE71FN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import library\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdnNc1X__Qyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creat dataframe\n",
        "df_train = pd.read_csv('/content/train - train.csv')\n",
        "df_test = pd.read_csv('/content/test - test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAmx3NqmqO1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fill 2 nan row\n",
        "df_test.fillna('a', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q-XbVF0Ns_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fill 2 nan row\n",
        "df_train.fillna('a', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPYhW12EQ5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function clean text\n",
        "def preprocessor(text):\n",
        "  text = re.sub(\"do 'nt\", 'do not', text)\n",
        "  text = re.sub(\"'d\", 'had', text)\n",
        "  text = re.sub(\"n't\", 'not', text)\n",
        "  text = re.sub(\"re\", 'are', text)\n",
        "  text = re.sub(\"'m\", 'am', text)\n",
        "  text = re.sub(\"'s\", 'is', text)\n",
        "  text = re.sub(\"n't\", 'not', text)\n",
        "  text = re.sub(\"[?,.!@=+-;'`˜`ˆ\bˆ&*]\", '', text)\n",
        "  text = re.sub(\"ˆ[a-zA-Z]+\",'', text.lower())\n",
        "  return text.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJFLNqBHrzGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean test dataset\n",
        "test_list = []\n",
        "for sentence in df_test['Phrase'].values:\n",
        "  test_list.append(preprocessor(str(sentence)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTKoTZSwyap4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add clean list to dataframe\n",
        "test_list = pd.Series(test_list)\n",
        "df_test['Phrase'] = test_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvUPP6UkPoBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean test dataset\n",
        "train_test = []\n",
        "for sentence in df_train['Phrase'].values:\n",
        "  train_test.append(preprocessor(str(sentence)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWyBsQwhBkUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add clean list to dataframe\n",
        "train_test = pd.Series(train_test)\n",
        "df_train['Phrase'] = train_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZvanLtDyeEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concat 2 columns together\n",
        "df = pd.concat([df_train['Phrase'], df_test['Phrase']],ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhOXjIJ_a1Uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count word\n",
        "count = Counter()\n",
        "for word in train_test:\n",
        "  for j in word.split():\n",
        "    count[j] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejoi5x8Tf3b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhbVIQDWgC9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count word same in stop word\n",
        "vocab_reduced = Counter()\n",
        "for i in count.items():\n",
        "  if i[0] not in stop:\n",
        "    vocab_reduced[i[0]] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vRw7pLgghoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer word\n",
        "porter = PorterStemmer()\n",
        "def tokenizer_porter(text):\n",
        "  token = []\n",
        "  for i in text.split():\n",
        "    token.append(porter.stem(i))\n",
        "  \n",
        "  return token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvkj4M1XsDoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create tfidf\n",
        "tfidf = TfidfVectorizer(stop_words=stop, tokenizer = tokenizer_porter, preprocessor= preprocessor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeuIzk3Bz-ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn values\n",
        "tfidf.fit(df.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa-CeBOz0Vrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creat 2 series\n",
        "training = df[:len(df_train)]\n",
        "testing = df[len(df_train):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CDbv3Z-0yRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training model and vectorizer\n",
        "training_vector = tfidf.transform(df_train['Phrase'].values)\n",
        "testing_vector = tfidf.transform(testing.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj2mhIndrWfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logistic regression\n",
        "X = training_vector\n",
        "y = training['Sentiment']\n",
        "lg = LogisticRegression()\n",
        "lg.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-_5uC1O67Nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction\n",
        "y_pred = lg.predict(testing_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kqqj8Hw62HZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output upto kaggle\n",
        "def create_output(y_pred):\n",
        "    data = {\n",
        "        'PhraseId': df_test['PhraseId'].values,\n",
        "        'Sentiment': y_pred\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('output.csv', index=False)\n",
        "    return\n",
        "\n",
        "create_output(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}